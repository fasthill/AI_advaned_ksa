{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "friendly-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "controlled-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sharp-degree",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " 0   PassengerId  탑승자 일련번호  \n",
    " 1   Survived     생존여부 0: 사망, 1: 생존 \n",
    " 2   Pclass       티켓의 선실 등급 / 1등급, 2등급, 3등급\n",
    " 3   Name         탑승자 이름\n",
    " 4   Sex          탑승자 성별 \n",
    " 5   Age          탑승자 나이\n",
    " 6   SibSp        같이 탑승한 형제 자매 또는 배우자의 수 \n",
    " 7   Parch        같이 탑승한 부모님 또는 어린아이 수  \n",
    " 8   Ticket       티켓 일련 번호\n",
    " 9   Fare         요금\n",
    " 10  Cabin        선실번호\n",
    " 11  Embarked     중간 정착항구\n",
    "    \n",
    "[딥러닝 실습]\n",
    "1. 전처리 작업\n",
    "\n",
    " 1) 11개의 독립변수 중 생존여부와 관련 없는 변수는 무엇인가?  ; 탑승자 일련번호 df.corr()에서\n",
    " \n",
    " 2) 문자열 컬럼은 무엇인가? : 성별, 정박항구, cabin, name, ticket\n",
    " \n",
    " 3) 결측치가 존재하는 컴럼은 어떤 값으로 대체하여야 하는가?\n",
    "    Age: 평균값 처리\n",
    "    cabin: 첫번째 문자만 남기고 나머지 문자 제거, 결측치 값은 N 값으로 설정\n",
    "    Embarked: 결측치 값은 N 값을 설정\n",
    "    \n",
    "2. 훈련 데이터와 테스트 데이터 생성\n",
    "3. 모델 생성 및 학습\n",
    "4. 검증 정확도 80% 이상 확보\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "durable-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Survived']\n",
    "df = df[new_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "auburn-bridal",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      N\n",
       "1      C\n",
       "2      N\n",
       "3      C\n",
       "4      N\n",
       "      ..\n",
       "886    N\n",
       "887    B\n",
       "888    N\n",
       "889    C\n",
       "890    N\n",
       "Name: Cabin, Length: 891, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cabin'] = df['Cabin'].str[0]\n",
    "df['Cabin'] = df['Cabin'].fillna('N') # cabin 결측치 처리\n",
    "df['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "exotic-container",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "   Sex   Age  SibSp  Parch            Ticket     Fare  Cabin  Embarked  \\\n",
       "0    1  22.0      1      0         A/5 21171   7.2500      7         2   \n",
       "1    0  38.0      1      0          PC 17599  71.2833      2         0   \n",
       "2    0  26.0      0      0  STON/O2. 3101282   7.9250      7         2   \n",
       "3    0  35.0      1      0            113803  53.1000      2         2   \n",
       "4    1  35.0      0      0            373450   8.0500      7         2   \n",
       "\n",
       "   Survived  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = LabelEncoder()\n",
    "e.fit(df['Sex'])\n",
    "df['Sex'] = e.transform(df['Sex'])\n",
    "e.fit(df['Embarked'])\n",
    "df['Embarked'] = e.transform(df['Embarked'])\n",
    "e.fit(df['Cabin'])\n",
    "df['Cabin'] = e.transform(df['Cabin'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "royal-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "pacific-choice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "   Sex   Age  SibSp  Parch            Ticket     Fare  Cabin  Embarked  \\\n",
       "0    1  22.0      1      0         A/5 21171   7.2500      7         2   \n",
       "1    0  38.0      1      0          PC 17599  71.2833      2         0   \n",
       "2    0  26.0      0      0  STON/O2. 3101282   7.9250      7         2   \n",
       "3    0  35.0      1      0            113803  53.1000      2         2   \n",
       "4    1  35.0      0      0            373450   8.0500      7         2   \n",
       "\n",
       "   Survived  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "lesbian-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Name         891 non-null    object \n",
      " 3   Sex          891 non-null    int64  \n",
      " 4   Age          891 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Cabin        891 non-null    int32  \n",
      " 10  Embarked     891 non-null    int64  \n",
      " 11  Survived     891 non-null    int64  \n",
      "dtypes: float64(2), int32(1), int64(7), object(2)\n",
      "memory usage: 80.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "medical-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.042939</td>\n",
       "      <td>0.033207</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.033080</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>-0.005007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.331339</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.742093</td>\n",
       "      <td>0.157112</td>\n",
       "      <td>-0.338481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.042939</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>0.118635</td>\n",
       "      <td>0.104057</td>\n",
       "      <td>-0.543351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.033207</td>\n",
       "      <td>-0.331339</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.232625</td>\n",
       "      <td>-0.179191</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>-0.249098</td>\n",
       "      <td>-0.022239</td>\n",
       "      <td>-0.069809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.232625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.041058</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>-0.035322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.179191</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>-0.031553</td>\n",
       "      <td>0.038322</td>\n",
       "      <td>0.081629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.525742</td>\n",
       "      <td>-0.221226</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>-0.033080</td>\n",
       "      <td>0.742093</td>\n",
       "      <td>0.118635</td>\n",
       "      <td>-0.249098</td>\n",
       "      <td>0.041058</td>\n",
       "      <td>-0.031553</td>\n",
       "      <td>-0.525742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191973</td>\n",
       "      <td>-0.295113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.157112</td>\n",
       "      <td>0.104057</td>\n",
       "      <td>-0.022239</td>\n",
       "      <td>0.066654</td>\n",
       "      <td>0.038322</td>\n",
       "      <td>-0.221226</td>\n",
       "      <td>0.191973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.163517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>-0.069809</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.295113</td>\n",
       "      <td>-0.163517</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId    Pclass       Sex       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.035144  0.042939  0.033207 -0.057527 -0.001652   \n",
       "Pclass         -0.035144  1.000000  0.131900 -0.331339  0.083081  0.018443   \n",
       "Sex             0.042939  0.131900  1.000000  0.084153 -0.114631 -0.245489   \n",
       "Age             0.033207 -0.331339  0.084153  1.000000 -0.232625 -0.179191   \n",
       "SibSp          -0.057527  0.083081 -0.114631 -0.232625  1.000000  0.414838   \n",
       "Parch          -0.001652  0.018443 -0.245489 -0.179191  0.414838  1.000000   \n",
       "Fare            0.012658 -0.549500 -0.182333  0.091566  0.159651  0.216225   \n",
       "Cabin          -0.033080  0.742093  0.118635 -0.249098  0.041058 -0.031553   \n",
       "Embarked        0.013083  0.157112  0.104057 -0.022239  0.066654  0.038322   \n",
       "Survived       -0.005007 -0.338481 -0.543351 -0.069809 -0.035322  0.081629   \n",
       "\n",
       "                 Fare     Cabin  Embarked  Survived  \n",
       "PassengerId  0.012658 -0.033080  0.013083 -0.005007  \n",
       "Pclass      -0.549500  0.742093  0.157112 -0.338481  \n",
       "Sex         -0.182333  0.118635  0.104057 -0.543351  \n",
       "Age          0.091566 -0.249098 -0.022239 -0.069809  \n",
       "SibSp        0.159651  0.041058  0.066654 -0.035322  \n",
       "Parch        0.216225 -0.031553  0.038322  0.081629  \n",
       "Fare         1.000000 -0.525742 -0.221226  0.257307  \n",
       "Cabin       -0.525742  1.000000  0.191973 -0.295113  \n",
       "Embarked    -0.221226  0.191973  1.000000 -0.163517  \n",
       "Survived     0.257307 -0.295113 -0.163517  1.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dried-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked  Survived\n",
       "0       3    1  22.0      1      0   7.2500      7         2         0\n",
       "1       1    0  38.0      1      0  71.2833      2         0         1\n",
       "2       3    0  26.0      0      0   7.9250      7         2         1\n",
       "3       1    0  35.0      1      0  53.1000      2         2         1\n",
       "4       3    1  35.0      0      0   8.0500      7         2         0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column_arange = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch','Fare', 'Cabin', 'Embarked', 'Survived']\n",
    "df = df[new_column_arange]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "traditional-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "voluntary-document",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dominican-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model_titanic/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "modelpath = MODEL_DIR + \"{epoch:02d}-{val_loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adequate-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "X = dataset[:, :8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "greek-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-protection",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim=8, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "liable-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "strange-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "stopping = EarlyStopping(monitor='val_loss', patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "absent-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "22/22 [==============================] - 2s 21ms/step - loss: 1.7000 - accuracy: 0.5619 - val_loss: 0.9494 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.94944, saving model to ./model_titanic\\01-0.9494.hdf5\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7075 - accuracy: 0.6491 - val_loss: 0.7000 - val_accuracy: 0.6791\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.94944 to 0.70003, saving model to ./model_titanic\\02-0.7000.hdf5\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6537 - accuracy: 0.6812 - val_loss: 0.6472 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70003 to 0.64718, saving model to ./model_titanic\\03-0.6472.hdf5\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.6995 - val_loss: 0.6299 - val_accuracy: 0.6791\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64718 to 0.62990, saving model to ./model_titanic\\04-0.6299.hdf5\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.7064 - val_loss: 0.6290 - val_accuracy: 0.6631\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.62990 to 0.62900, saving model to ./model_titanic\\05-0.6290.hdf5\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5987 - accuracy: 0.7110 - val_loss: 0.5979 - val_accuracy: 0.6952\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62900 to 0.59791, saving model to ./model_titanic\\06-0.5979.hdf5\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5653 - accuracy: 0.7523 - val_loss: 0.5890 - val_accuracy: 0.7166\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.59791 to 0.58904, saving model to ./model_titanic\\07-0.5890.hdf5\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.5672 - accuracy: 0.7248 - val_loss: 0.6138 - val_accuracy: 0.7059\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.58904\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5581 - accuracy: 0.7523 - val_loss: 0.5852 - val_accuracy: 0.7166\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.58904 to 0.58525, saving model to ./model_titanic\\09-0.5852.hdf5\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5498 - accuracy: 0.7339 - val_loss: 0.5971 - val_accuracy: 0.7059\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.58525\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7454 - val_loss: 0.5580 - val_accuracy: 0.7166\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.58525 to 0.55796, saving model to ./model_titanic\\11-0.5580.hdf5\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7569 - val_loss: 0.5698 - val_accuracy: 0.7219\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.55796\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4999 - accuracy: 0.7615 - val_loss: 0.5592 - val_accuracy: 0.7219\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.55796\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7638 - val_loss: 0.5504 - val_accuracy: 0.7273\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.55796 to 0.55043, saving model to ./model_titanic\\14-0.5504.hdf5\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.4942 - accuracy: 0.7569 - val_loss: 0.5252 - val_accuracy: 0.7326\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.55043 to 0.52520, saving model to ./model_titanic\\15-0.5252.hdf5\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.5025 - accuracy: 0.7592 - val_loss: 0.5406 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.52520\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.4802 - accuracy: 0.7661 - val_loss: 0.5159 - val_accuracy: 0.7433\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.52520 to 0.51586, saving model to ./model_titanic\\17-0.5159.hdf5\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.4841 - accuracy: 0.7523 - val_loss: 0.5251 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51586\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.4644 - accuracy: 0.7844 - val_loss: 0.5055 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51586 to 0.50553, saving model to ./model_titanic\\19-0.5055.hdf5\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.4612 - accuracy: 0.7775 - val_loss: 0.5032 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.50553 to 0.50323, saving model to ./model_titanic\\20-0.5032.hdf5\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4515 - accuracy: 0.7752 - val_loss: 0.5072 - val_accuracy: 0.7540\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.50323\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4485 - accuracy: 0.7592 - val_loss: 0.5365 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.50323\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.4530 - accuracy: 0.7867 - val_loss: 0.5644 - val_accuracy: 0.7326\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.50323\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.4478 - accuracy: 0.7798 - val_loss: 0.4891 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.50323 to 0.48910, saving model to ./model_titanic\\24-0.4891.hdf5\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4346 - accuracy: 0.8050 - val_loss: 0.5096 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.48910\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4985 - accuracy: 0.7661 - val_loss: 0.5187 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.48910\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4629 - accuracy: 0.7844 - val_loss: 0.5235 - val_accuracy: 0.7540\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.48910\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4308 - accuracy: 0.7959 - val_loss: 0.4828 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.48910 to 0.48276, saving model to ./model_titanic\\28-0.4828.hdf5\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4368 - accuracy: 0.8050 - val_loss: 0.5286 - val_accuracy: 0.7540\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.48276\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.4469 - accuracy: 0.8005 - val_loss: 0.4861 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.48276\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.4317 - accuracy: 0.7936 - val_loss: 0.5044 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.48276\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7821 - val_loss: 0.4964 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.48276\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7867 - val_loss: 0.4930 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.48276\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7890 - val_loss: 0.5483 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.48276\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4694 - accuracy: 0.7913 - val_loss: 0.5311 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.48276\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4253 - accuracy: 0.7936 - val_loss: 0.4767 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.48276 to 0.47673, saving model to ./model_titanic\\36-0.4767.hdf5\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8165 - val_loss: 0.4825 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.47673\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8119 - val_loss: 0.4813 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.47673\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.8119 - val_loss: 0.5195 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.47673\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4270 - accuracy: 0.7913 - val_loss: 0.5063 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.47673\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8005 - val_loss: 0.5328 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.47673\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7959 - val_loss: 0.4868 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.47673\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8211 - val_loss: 0.4958 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.47673\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4309 - accuracy: 0.8234 - val_loss: 0.4985 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.47673\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.8028 - val_loss: 0.5468 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.47673\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.8073 - val_loss: 0.5371 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.47673\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8028 - val_loss: 0.5077 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.47673\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8119 - val_loss: 0.5070 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.47673\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7706 - val_loss: 0.4740 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.47673 to 0.47398, saving model to ./model_titanic\\49-0.4740.hdf5\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7959 - val_loss: 0.4653 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.47398 to 0.46529, saving model to ./model_titanic\\50-0.4653.hdf5\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8073 - val_loss: 0.5997 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.46529\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8096 - val_loss: 0.4719 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.46529\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8050 - val_loss: 0.5342 - val_accuracy: 0.7540\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.46529\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8211 - val_loss: 0.4985 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.46529\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8096 - val_loss: 0.5018 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.46529\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.4752 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.46529\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8211 - val_loss: 0.5060 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.46529\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8050 - val_loss: 0.4665 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.46529\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8073 - val_loss: 0.4765 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.46529\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8257 - val_loss: 0.4707 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.46529\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4119 - accuracy: 0.8211 - val_loss: 0.5352 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.46529\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8165 - val_loss: 0.4829 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.46529\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8211 - val_loss: 0.4783 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.46529\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.7913 - val_loss: 0.5790 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.46529\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8257 - val_loss: 0.4824 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.46529\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8142 - val_loss: 0.4832 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.46529\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8096 - val_loss: 0.4676 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.46529\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8028 - val_loss: 0.5023 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.46529\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8303 - val_loss: 0.4605 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.46529 to 0.46047, saving model to ./model_titanic\\69-0.4605.hdf5\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8188 - val_loss: 0.4913 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.46047\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8234 - val_loss: 0.4722 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.46047\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8119 - val_loss: 0.5042 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.46047\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8096 - val_loss: 0.4602 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.46047 to 0.46025, saving model to ./model_titanic\\73-0.4602.hdf5\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8073 - val_loss: 0.4591 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.46025 to 0.45906, saving model to ./model_titanic\\74-0.4591.hdf5\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8050 - val_loss: 0.4692 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.45906\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8005 - val_loss: 0.6093 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.45906\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8142 - val_loss: 0.5089 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.45906\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.7982 - val_loss: 0.4848 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.45906\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8280 - val_loss: 0.4840 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.45906\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8303 - val_loss: 0.4603 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.45906\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4060 - accuracy: 0.8326 - val_loss: 0.4629 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.45906\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.4071 - accuracy: 0.8303 - val_loss: 0.4550 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.45906 to 0.45504, saving model to ./model_titanic\\82-0.4550.hdf5\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.8028 - val_loss: 0.4651 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.45504\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.4968 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.45504\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8142 - val_loss: 0.4872 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.45504\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4134 - accuracy: 0.8142 - val_loss: 0.4887 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.45504\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8211 - val_loss: 0.4940 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.45504\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8234 - val_loss: 0.4576 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.45504\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8142 - val_loss: 0.4661 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.45504\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.4261 - accuracy: 0.8280 - val_loss: 0.5071 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.45504\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8257 - val_loss: 0.4562 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.45504\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8142 - val_loss: 0.4499 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.45504 to 0.44985, saving model to ./model_titanic\\92-0.4499.hdf5\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8211 - val_loss: 0.4533 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.44985\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8211 - val_loss: 0.4569 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.44985\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.3865 - accuracy: 0.8280 - val_loss: 0.4651 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.44985\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8303 - val_loss: 0.5137 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.44985\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8188 - val_loss: 0.4627 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.44985\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.8165 - val_loss: 0.5802 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.44985\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4226 - accuracy: 0.8188 - val_loss: 0.4563 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.44985\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.7982 - val_loss: 0.4806 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.44985\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8257 - val_loss: 0.4460 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.44985 to 0.44596, saving model to ./model_titanic\\101-0.4460.hdf5\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8211 - val_loss: 0.4843 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.44596\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8119 - val_loss: 0.5001 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.44596\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8234 - val_loss: 0.4612 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.44596\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8188 - val_loss: 0.5250 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.44596\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.8142 - val_loss: 0.4700 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.44596\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8326 - val_loss: 0.4748 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.44596\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.4908 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.44596\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8234 - val_loss: 0.4647 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.44596\n",
      "Epoch 110/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8211 - val_loss: 0.4563 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.44596\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8234 - val_loss: 0.4416 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.44596 to 0.44155, saving model to ./model_titanic\\111-0.4416.hdf5\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8257 - val_loss: 0.4764 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.44155\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8486 - val_loss: 0.4445 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.44155\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8211 - val_loss: 0.4847 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.44155\n",
      "Epoch 115/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8257 - val_loss: 0.4744 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.44155\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.3972 - accuracy: 0.8303 - val_loss: 0.5108 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.44155\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8165 - val_loss: 0.4600 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.44155\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8096 - val_loss: 0.4562 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.44155\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8211 - val_loss: 0.4585 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.44155\n",
      "Epoch 120/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8142 - val_loss: 0.4752 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.44155\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8280 - val_loss: 0.4526 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.44155\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8165 - val_loss: 0.4533 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.44155\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8211 - val_loss: 0.4627 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.44155\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8303 - val_loss: 0.4474 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.44155\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8280 - val_loss: 0.4799 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.44155\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8119 - val_loss: 0.4939 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.44155\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8211 - val_loss: 0.5245 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.44155\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8257 - val_loss: 0.4941 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.44155\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8211 - val_loss: 0.5001 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.44155\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8211 - val_loss: 0.4532 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.44155\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8257 - val_loss: 0.4651 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.44155\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8280 - val_loss: 0.4515 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.44155\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8142 - val_loss: 0.4500 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.44155\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8234 - val_loss: 0.4641 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.44155\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8211 - val_loss: 0.4910 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.44155\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8349 - val_loss: 0.5590 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.44155\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8234 - val_loss: 0.4810 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.44155\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8165 - val_loss: 0.4635 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.44155\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8165 - val_loss: 0.4677 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.44155\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8234 - val_loss: 0.5067 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.44155\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8165 - val_loss: 0.4811 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.44155\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8073 - val_loss: 0.5666 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.44155\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.8028 - val_loss: 0.4807 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.44155\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8188 - val_loss: 0.4428 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.44155\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8280 - val_loss: 0.4767 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.44155\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8096 - val_loss: 0.4831 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.44155\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8211 - val_loss: 0.5423 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.44155\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8234 - val_loss: 0.5088 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.44155\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8280 - val_loss: 0.5904 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.44155\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8280 - val_loss: 0.4688 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.44155\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8234 - val_loss: 0.4531 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.44155\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8372 - val_loss: 0.4690 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.44155\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8257 - val_loss: 0.4558 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.44155\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8096 - val_loss: 0.4504 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.44155\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8280 - val_loss: 0.5784 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.44155\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8234 - val_loss: 0.4835 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.44155\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8188 - val_loss: 0.5217 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.44155\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8050 - val_loss: 0.4475 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.44155\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.8050 - val_loss: 0.4693 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.44155\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8142 - val_loss: 0.4755 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.44155\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8303 - val_loss: 0.5134 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.44155\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8188 - val_loss: 0.5133 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.44155\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8234 - val_loss: 0.4523 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.44155\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8280 - val_loss: 0.4894 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.44155\n",
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8326 - val_loss: 0.4456 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.44155\n",
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8280 - val_loss: 0.4863 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.44155\n",
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8303 - val_loss: 0.5509 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.44155\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8257 - val_loss: 0.4598 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.44155\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8165 - val_loss: 0.4648 - val_accuracy: 0.8235\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.44155\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8188 - val_loss: 0.4718 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.44155\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8165 - val_loss: 0.4424 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.44155\n",
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8349 - val_loss: 0.4507 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.44155\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.8372 - val_loss: 0.5288 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.44155\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8326 - val_loss: 0.4742 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.44155\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8211 - val_loss: 0.4962 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.44155\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8234 - val_loss: 0.4519 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.44155\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3739 - accuracy: 0.8349 - val_loss: 0.4541 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.44155\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8234 - val_loss: 0.4392 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.44155 to 0.43917, saving model to ./model_titanic\\178-0.4392.hdf5\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8073 - val_loss: 0.4749 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.43917\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8303 - val_loss: 0.4444 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.43917\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8234 - val_loss: 0.4771 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.43917\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8211 - val_loss: 0.4640 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.43917\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8257 - val_loss: 0.4836 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.43917\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8326 - val_loss: 0.5341 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.43917\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8303 - val_loss: 0.4519 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.43917\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8188 - val_loss: 0.4685 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.43917\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3778 - accuracy: 0.8280 - val_loss: 0.5945 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.43917\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8234 - val_loss: 0.5731 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.43917\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8234 - val_loss: 0.4435 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.43917\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8234 - val_loss: 0.4718 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.43917\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.3662 - accuracy: 0.8372 - val_loss: 0.4516 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.43917\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8234 - val_loss: 0.4639 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.43917\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8303 - val_loss: 0.4678 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.43917\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8372 - val_loss: 0.5580 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.43917\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8303 - val_loss: 0.4456 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.43917\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8234 - val_loss: 0.4938 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.43917\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8303 - val_loss: 0.4444 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.43917\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8050 - val_loss: 0.5312 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.43917\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8028 - val_loss: 0.4787 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.43917\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8280 - val_loss: 0.4854 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.43917\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8326 - val_loss: 0.4420 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.43917\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8349 - val_loss: 0.4462 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.43917\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8165 - val_loss: 0.4479 - val_accuracy: 0.7861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00203: val_loss did not improve from 0.43917\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8326 - val_loss: 0.4665 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.43917\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8303 - val_loss: 0.4866 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.43917\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8280 - val_loss: 0.5671 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.43917\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8326 - val_loss: 0.4918 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.43917\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8372 - val_loss: 0.4411 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.43917\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8142 - val_loss: 0.5663 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.43917\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8188 - val_loss: 0.4534 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.43917\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8234 - val_loss: 0.4549 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.43917\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8326 - val_loss: 0.4556 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.43917\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8372 - val_loss: 0.4514 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.43917\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8303 - val_loss: 0.4514 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.43917\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8188 - val_loss: 0.4920 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.43917\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8211 - val_loss: 0.4566 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.43917\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8257 - val_loss: 0.4700 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.43917\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3686 - accuracy: 0.8280 - val_loss: 0.4536 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.43917\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8417 - val_loss: 0.4529 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.43917\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8349 - val_loss: 0.4616 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.43917\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8234 - val_loss: 0.4630 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.43917\n",
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8394 - val_loss: 0.4856 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.43917\n",
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8303 - val_loss: 0.4456 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.43917\n",
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8349 - val_loss: 0.4958 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.43917\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8349 - val_loss: 0.5254 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.43917\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8440 - val_loss: 0.4443 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.43917\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8257 - val_loss: 0.4592 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.43917\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8165 - val_loss: 0.4756 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.43917\n",
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8394 - val_loss: 0.4392 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.43917\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8303 - val_loss: 0.4889 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.43917\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8394 - val_loss: 0.5203 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.43917\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8394 - val_loss: 0.4667 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.43917\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.8234 - val_loss: 0.4481 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.43917\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3597 - accuracy: 0.8372 - val_loss: 0.4493 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.43917\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8372 - val_loss: 0.4597 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.43917\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8280 - val_loss: 0.4566 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.43917\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8165 - val_loss: 0.4681 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.43917\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8303 - val_loss: 0.4705 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.43917\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8211 - val_loss: 0.4783 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.43917\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8417 - val_loss: 0.4784 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.43917\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3589 - accuracy: 0.8463 - val_loss: 0.5343 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.43917\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8257 - val_loss: 0.5004 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.43917\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8188 - val_loss: 0.4625 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.43917\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3532 - accuracy: 0.8509 - val_loss: 0.4666 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.43917\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3548 - accuracy: 0.8349 - val_loss: 0.4546 - val_accuracy: 0.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00245: val_loss did not improve from 0.43917\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8440 - val_loss: 0.4547 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.43917\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8257 - val_loss: 0.4647 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.43917\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3594 - accuracy: 0.8463 - val_loss: 0.4563 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.43917\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8349 - val_loss: 0.4738 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.43917\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.3807 - accuracy: 0.8417 - val_loss: 0.4922 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.43917\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3499 - accuracy: 0.8440 - val_loss: 0.4454 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.43917\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3491 - accuracy: 0.8280 - val_loss: 0.4638 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.43917\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3456 - accuracy: 0.8417 - val_loss: 0.4762 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.43917\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8394 - val_loss: 0.4604 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.43917\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8211 - val_loss: 0.4885 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.43917\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8372 - val_loss: 0.4862 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.43917\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.81 - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8165 - val_loss: 0.4433 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.43917\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8326 - val_loss: 0.4505 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.43917\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8303 - val_loss: 0.5225 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.43917\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3622 - accuracy: 0.8372 - val_loss: 0.5046 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.43917\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8394 - val_loss: 0.4593 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.43917\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3645 - accuracy: 0.8372 - val_loss: 0.4568 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.43917\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8509 - val_loss: 0.4821 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.43917\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8303 - val_loss: 0.4507 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.43917\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8486 - val_loss: 0.4887 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.43917\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3471 - accuracy: 0.8463 - val_loss: 0.4650 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.43917\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8440 - val_loss: 0.4683 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.43917\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3541 - accuracy: 0.8326 - val_loss: 0.4954 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.43917\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3440 - accuracy: 0.8486 - val_loss: 0.4608 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.43917\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3417 - accuracy: 0.8784 - val_loss: 0.4812 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.43917\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3746 - accuracy: 0.8326 - val_loss: 0.5308 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.43917\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8394 - val_loss: 0.5248 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.43917\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8394 - val_loss: 0.4546 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.43917\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8394 - val_loss: 0.5013 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.43917\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8463 - val_loss: 0.4599 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.43917\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8486 - val_loss: 0.4431 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.43917\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8349 - val_loss: 0.4467 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.43917\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8234 - val_loss: 0.5406 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.43917\n",
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8372 - val_loss: 0.4818 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.43917\n",
      "Epoch 280/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3586 - accuracy: 0.8440 - val_loss: 0.4669 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.43917\n",
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8486 - val_loss: 0.4604 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.43917\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8440 - val_loss: 0.4886 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.43917\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3441 - accuracy: 0.8486 - val_loss: 0.4504 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.43917\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8463 - val_loss: 0.5225 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.43917\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8463 - val_loss: 0.4944 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.43917\n",
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8303 - val_loss: 0.4742 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.43917\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3522 - accuracy: 0.8486 - val_loss: 0.4642 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.43917\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8372 - val_loss: 0.5073 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.43917\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3575 - accuracy: 0.8188 - val_loss: 0.4837 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.43917\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8532 - val_loss: 0.4522 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.43917\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8280 - val_loss: 0.4461 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.43917\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8326 - val_loss: 0.5018 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.43917\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.8372 - val_loss: 0.4545 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.43917\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8463 - val_loss: 0.4577 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.43917\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8624 - val_loss: 0.5031 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.43917\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8417 - val_loss: 0.5000 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.43917\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8372 - val_loss: 0.4643 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.43917\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8532 - val_loss: 0.5030 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.43917\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8326 - val_loss: 0.5869 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.43917\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3580 - accuracy: 0.8555 - val_loss: 0.5612 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.43917\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8440 - val_loss: 0.4694 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.43917\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.8349 - val_loss: 0.4900 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.43917\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3391 - accuracy: 0.8509 - val_loss: 0.4543 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.43917\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3380 - accuracy: 0.8486 - val_loss: 0.5099 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.43917\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3355 - accuracy: 0.8532 - val_loss: 0.4883 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.43917\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3449 - accuracy: 0.8509 - val_loss: 0.4662 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.43917\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3343 - accuracy: 0.8601 - val_loss: 0.6067 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.43917\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8372 - val_loss: 0.4603 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.43917\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8326 - val_loss: 0.5097 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.43917\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3539 - accuracy: 0.8349 - val_loss: 0.4648 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.43917\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3395 - accuracy: 0.8509 - val_loss: 0.4733 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.43917\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3394 - accuracy: 0.8624 - val_loss: 0.4598 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.43917\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3550 - accuracy: 0.8349 - val_loss: 0.4762 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.43917\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3383 - accuracy: 0.8578 - val_loss: 0.4706 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.43917\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.8532 - val_loss: 0.4651 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.43917\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8532 - val_loss: 0.4817 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.43917\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8532 - val_loss: 0.4734 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.43917\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8532 - val_loss: 0.4715 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.43917\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3421 - accuracy: 0.8509 - val_loss: 0.4723 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.43917\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3425 - accuracy: 0.8578 - val_loss: 0.4940 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.43917\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3736 - accuracy: 0.8188 - val_loss: 0.4539 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.43917\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8486 - val_loss: 0.5493 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.43917\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8440 - val_loss: 0.4797 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.43917\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3469 - accuracy: 0.8440 - val_loss: 0.4856 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.43917\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8578 - val_loss: 0.4569 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.43917\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3314 - accuracy: 0.8486 - val_loss: 0.4905 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.43917\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3307 - accuracy: 0.8417 - val_loss: 0.4753 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.43917\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8555 - val_loss: 0.4639 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.43917\n",
      "Epoch 329/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.8417 - val_loss: 0.5264 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.43917\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8463 - val_loss: 0.4852 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.43917\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3400 - accuracy: 0.8555 - val_loss: 0.4714 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.43917\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8555 - val_loss: 0.4705 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.43917\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3226 - accuracy: 0.8555 - val_loss: 0.4768 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.43917\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3409 - accuracy: 0.8486 - val_loss: 0.4724 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.43917\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3269 - accuracy: 0.8532 - val_loss: 0.4835 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.43917\n",
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8463 - val_loss: 0.4549 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.43917\n",
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8555 - val_loss: 0.4787 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.43917\n",
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3401 - accuracy: 0.8578 - val_loss: 0.4994 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.43917\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3510 - accuracy: 0.8326 - val_loss: 0.4625 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.43917\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8601 - val_loss: 0.4812 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.43917\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3345 - accuracy: 0.8601 - val_loss: 0.4976 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.43917\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8486 - val_loss: 0.4670 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.43917\n",
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3372 - accuracy: 0.8509 - val_loss: 0.4915 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.43917\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8486 - val_loss: 0.5400 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.43917\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3426 - accuracy: 0.8417 - val_loss: 0.4514 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.43917\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8532 - val_loss: 0.4764 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.43917\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3252 - accuracy: 0.8555 - val_loss: 0.5227 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.43917\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8532 - val_loss: 0.4756 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.43917\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3234 - accuracy: 0.8578 - val_loss: 0.4701 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.43917\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3239 - accuracy: 0.8463 - val_loss: 0.5036 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.43917\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8486 - val_loss: 0.4840 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.43917\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8372 - val_loss: 0.5168 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.43917\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3304 - accuracy: 0.8647 - val_loss: 0.4798 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.43917\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3244 - accuracy: 0.8555 - val_loss: 0.4519 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.43917\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3282 - accuracy: 0.8601 - val_loss: 0.4577 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.43917\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3288 - accuracy: 0.8578 - val_loss: 0.4869 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.43917\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8372 - val_loss: 0.6116 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.43917\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8303 - val_loss: 0.5016 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.43917\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8578 - val_loss: 0.5108 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.43917\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3432 - accuracy: 0.8394 - val_loss: 0.4675 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.43917\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8555 - val_loss: 0.4530 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.43917\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3241 - accuracy: 0.8624 - val_loss: 0.4811 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.43917\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8578 - val_loss: 0.4892 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.43917\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8440 - val_loss: 0.4634 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.43917\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8578 - val_loss: 0.5365 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.43917\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3403 - accuracy: 0.8440 - val_loss: 0.4597 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.43917\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3152 - accuracy: 0.8555 - val_loss: 0.4892 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.43917\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3196 - accuracy: 0.8647 - val_loss: 0.4979 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.43917\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3399 - accuracy: 0.8463 - val_loss: 0.5019 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.43917\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8601 - val_loss: 0.4528 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.43917\n",
      "Epoch 371/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.8670 - val_loss: 0.5400 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.43917\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3555 - accuracy: 0.8440 - val_loss: 0.5403 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.43917\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8509 - val_loss: 0.4727 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.43917\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3222 - accuracy: 0.8739 - val_loss: 0.4688 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.43917\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3423 - accuracy: 0.8463 - val_loss: 0.5388 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.43917\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.8670 - val_loss: 0.4748 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.43917\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8509 - val_loss: 0.4594 - val_accuracy: 0.7914\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.43917\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8326 - val_loss: 0.5317 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.43917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_split=0.3, epochs=1000, batch_size=20, callbacks=[stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "copyrighted-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.5426, test_accuracy: 0.7799\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('./model_titanic/112-0.4492.hdf5')\n",
    "result = best_model.evaluate(X_test,Y_test, verbose=0)\n",
    "print('test loss: {:.4f}, test_accuracy: {:.4f}'.format(result[0], result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. 컬럼 삭제\n",
    "titanic_df = pd.read_csv('../data/titanic.csv')\n",
    "titanic_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "destroyed-henry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       891 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Cabin     204 non-null    object \n",
      " 8   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2. 결측치 처리하기 \n",
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "nutritional-facial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       891 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Cabin     891 non-null    object \n",
      " 8   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#3 결측치 처리하기 Cabin\n",
    "titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "\n",
    "titanic_df['Cabin'] = titani_df['Cabin'].str[:1fillna('N', inplace=True)\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 결측치 처리하기 Cabin\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
